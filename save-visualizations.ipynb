{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from jupyterthemes import jtplot\n",
    "import innvestigate\n",
    "import shap\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "from sklearn.preprocessing import normalize\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)\n",
    "from PIL import *\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "K.clear_session()\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob, os\n",
    "from matplotlib import image\n",
    "from skimage.transform import resize\n",
    "from PIL import Image, ImageChops, ImageDraw, ImageFont\n",
    "import math\n",
    "from matplotlib import rc\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('annot_keras_20.npy')\n",
    "#x_test = np.load('annot_keras.npy')\n",
    "#x_test = np.load('test_keras.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask = np.load('masks_keras.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'OCT-annotations/attributions_20_new/'\n",
    "#base = 'OCT-annotations/attributions/'\n",
    "base_out = 'OCT-annotations/output_paper/'\n",
    "base_img = 'OCT-annotations/images/'\n",
    "base_marked = 'OCT-annotations/abdul_markings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 deconvnet\n",
      "1 deep_taylor\n",
      "2 deeplift\n",
      "3 gradient\n",
      "4 guided_backprop\n",
      "5 input_t_gradient\n",
      "6 integrated_gradients\n",
      "7 lrp.epsilon\n",
      "8 lrp.z\n",
      "9 occlusion\n",
      "10 saliency\n",
      "11 shap_rand\n",
      "12 shap_select\n",
      "13 smoothgrad\n"
     ]
    }
   ],
   "source": [
    "explainers = ['shap_select', 'shap_rand', 'guided_backprop', 'deep_taylor', 'input_t_gradient', 'lrp.z', 'integrated_gradients',\n",
    "              'gradient', \"smoothgrad\", \"deconvnet\", 'deeplift', 'saliency', 'occlusion', 'lrp.epsilon']\n",
    "explainers.sort()\n",
    "for e, exp in enumerate(explainers):\n",
    "    print(e, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_labels = ['DcNet', 'D. Taylor', 'DLift-Res', 'Grad', 'G. Backprop', 'I*Grad', 'IG', 'LRP.E', 'LRP.Z', 'Occ64', 'Saliency', 'SHAP-R', 'SHAP-S', 'SmoothGrad']\n",
    "exp_dict = dict(zip(explainers, explainer_labels))\n",
    "#exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = ['CNV', 'DME', 'DRUSEN', 'Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_addrs = glob.glob('../Kermany_inception/top_weights/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = InceptionV3(include_top=True, weights= None, classes=4)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "weight_addrs = glob.glob('../Kermany_inception/top_weights/*')\n",
    "#model.load_weights(weight_addrs[7])\n",
    "model.load_weights(weight_addrs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_arr = []\n",
    "for cl in range(3):\n",
    "    pred_arr.append(model.predict(x_test[cl]))\n",
    "#pred_arr\n",
    "Y_pred = np.argmax(np.array(pred_arr), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot on images of original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(file):\n",
    "    #print(file)\n",
    "    for i, f in enumerate(file):\n",
    "        if f == \"-\":\n",
    "            break\n",
    "       # print(i)\n",
    "    return(file[i+1:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filepath = base_marked + dis[0] + \\'/\\'\\nfiles = []\\ndirs = os.listdir(filepath)\\ndirs.sort()\\nfilenames = []\\ncount = 0\\nfor file in dirs:\\n    if file.endswith(\".jpg\"):\\n        filenames.append(file)\\n        print(count, file)\\n        files.append(os.path.join(filepath, file))\\n        count+=1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"filepath = base_marked + dis[0] + '/'\n",
    "files = []\n",
    "dirs = os.listdir(filepath)\n",
    "dirs.sort()\n",
    "filenames = []\n",
    "count = 0\n",
    "for file in dirs:\n",
    "    if file.endswith(\".jpg\"):\n",
    "        filenames.append(file)\n",
    "        print(count, file)\n",
    "        files.append(os.path.join(filepath, file))\n",
    "        count+=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filepath = base_img + dis[0] + \\'/\\'\\nfiles = []\\ndirs = os.listdir(filepath)\\ndirs.sort()\\nfilenames = []\\ncount = 0\\nfor file in dirs:\\n    if file.endswith(\".jpeg\"):\\n        filenames.append(file)\\n        print(count, file)\\n        files.append(os.path.join(filepath, file))\\n        count+=1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"filepath = base_img + dis[0] + '/'\n",
    "files = []\n",
    "dirs = os.listdir(filepath)\n",
    "dirs.sort()\n",
    "filenames = []\n",
    "count = 0\n",
    "for file in dirs:\n",
    "    if file.endswith(\".jpeg\"):\n",
    "        filenames.append(file)\n",
    "        print(count, file)\n",
    "        files.append(os.path.join(filepath, file))\n",
    "        count+=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mark = [1, 8, 0]\n",
    "cat_img = [2, 12, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_marked(cat):\n",
    "    filepath = base_marked + dis[cat] + '/'\n",
    "    files = []\n",
    "    dirs = os.listdir(filepath)\n",
    "    dirs.sort()\n",
    "    filenames = []\n",
    "    for file in dirs:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            filenames.append(file)\n",
    "            files.append(os.path.join(filepath, file))\n",
    "    filename = get_id(filenames[cat_mark[cat]])\n",
    "    \n",
    "    img = plt.imread(files[cat_mark[cat]])\n",
    "    stacked_img = np.stack((img,)*3, axis=-1)\n",
    "    return stacked_img.astype('float'), filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(cat):\n",
    "    filepath = base_img + dis[cat] + '/'\n",
    "    files = []\n",
    "    dirs = os.listdir(filepath)\n",
    "    dirs.sort()\n",
    "    filenames = []\n",
    "    for file in dirs:\n",
    "        if file.endswith(\".jpeg\"):\n",
    "            filenames.append(file)\n",
    "            files.append(os.path.join(filepath, file))\n",
    "    filename = get_id(filenames[cat_img[cat]])\n",
    "    #print(filename)\n",
    "    #return plt.imread(files[num])\n",
    "    img = plt.imread(files[cat_img[cat]])\n",
    "    stacked_img = np.stack((img,)*3, axis=-1)\n",
    "    return stacked_img.astype('float'), filename\n",
    "    #return cv2.imread(files[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_text(img, exp):\n",
    "    w, h = img.size\n",
    "    d = ImageDraw.Draw(img)\n",
    "    fnt = ImageFont.truetype('arial.ttf', 60)\n",
    "    d.text((40, 25), exp, font = fnt, fill=(255,0,0))\n",
    "    return img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(org = 0):\n",
    "    im = Image.open(r\"tmp.png\")\n",
    "    w, h = im.size\n",
    "    print(w,h)\n",
    "    if(org == 1 or org == 2): #return original image\n",
    "        left = 0\n",
    "        right = w/2\n",
    "    else:\n",
    "        left = w/2\n",
    "        right = w\n",
    "    \n",
    "    \n",
    "    for i in range(int(left), int(left + 0.2*w), int(0.01*w)): #search left start\n",
    "        strip = im.crop((i, 0, i+10, h))\n",
    "        #print(strip)\n",
    "        extrema = strip.convert(\"L\").getextrema()\n",
    "        if extrema[0] == 0:\n",
    "            break     \n",
    "    \n",
    "    for j in range(int(right), int(right - 0.2*w), -int(0.01*w)): #search right end\n",
    "        strip = im.crop((j-10, 0, j, h))\n",
    "        #print(strip)\n",
    "        extrema = strip.convert(\"L\").getextrema()\n",
    "        if extrema[0] == 0:\n",
    "            break     \n",
    "            \n",
    "    if(org == 1):\n",
    "        im = im.crop((i, 0, j, h))\n",
    "        #put_text(im, \"OCT\")\n",
    "        #im.save(\"tmp_crop_org.png\")\n",
    "        return put_text(im, \"Prediction: \"+ dis[Y_pred[cat][num]])\n",
    "    elif(org == 2):\n",
    "        im = im.crop((i, 0, j, h))\n",
    "        #put_text(im, \"OCT\")\n",
    "        #im.save(\"tmp_crop_org.png\")\n",
    "        return put_text(im, \"Marking\")\n",
    "    im = im.crop((i, 0, j, h))\n",
    "    #put_text(im, exp)\n",
    "    #im.save(\"tmp_crop.png\")\n",
    "    \n",
    "    return put_text(im, exp_dict[exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "try:\n",
    "    import matplotlib.pyplot as pl\n",
    "except ImportError:\n",
    "    warnings.warn(\"matplotlib could not be loaded!\")\n",
    "    pass\n",
    "import colors\n",
    "\n",
    "def img_plot(shap_values, pixel_values,exp, org = 0, labels=None, width=40, aspect=0.2, hspace='auto', labelpad=None, show=False):\n",
    "    \"\"\" Plots SHAP values for image inputs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    shap_values : [numpy.array]\n",
    "        List of arrays of SHAP values. Each array has the shap (# samples x width x height x channels), and the\n",
    "        length of the list is equal to the number of model outputs that are being explained.\n",
    "    pixel_values : numpy.array\n",
    "        Matrix of pixel values (# samples x width x height x channels) for each image. It should be the same\n",
    "        shape as each array in the shap_values list of arrays.\n",
    "    labels : list\n",
    "        List of names for each of the model outputs that are being explained. This list should be the same length\n",
    "        as the shap_values list.\n",
    "    width : float\n",
    "        The width of the produced matplotlib plot.\n",
    "    labelpad : float\n",
    "        How much padding to use around the model output labels.\n",
    "    show : bool\n",
    "        Whether matplotlib.pyplot.show() is called before returning. Setting this to False allows the plot\n",
    "        to be customized further after it has been created.\n",
    "    \"\"\"\n",
    "\n",
    "    multi_output = True\n",
    "    if type(shap_values) != list:\n",
    "        multi_output = False\n",
    "        shap_values = [shap_values]\n",
    "\n",
    "    # make sure labels\n",
    "    if labels is not None:\n",
    "        assert labels.shape[0] == shap_values[0].shape[0], \"Labels must have same row count as shap_values arrays!\"\n",
    "        if multi_output:\n",
    "            assert labels.shape[1] == len(shap_values), \"Labels must have a column for each output in shap_values!\"\n",
    "        else:\n",
    "            assert len(labels.shape) == 1, \"Labels must be a vector for single output shap_values.\"\n",
    "\n",
    "    label_kwargs = {} if labelpad is None else {'pad': labelpad}\n",
    "\n",
    "    # plot our explanations\n",
    "    x = pixel_values\n",
    "    fig_size = np.array([17 * (len(shap_values) + 1), 3.2 * (x.shape[0] + 1)])\n",
    "    if fig_size[0] > width:\n",
    "        fig_size *= width / fig_size[0]\n",
    "    fig, axes = pl.subplots(nrows=x.shape[0], ncols=len(shap_values) + 1, figsize=fig_size)\n",
    "    fig.patch.set_facecolor('black')\n",
    "    if len(axes.shape) == 1:\n",
    "        axes = axes.reshape(1,axes.size)\n",
    "    for row in range(x.shape[0]):\n",
    "        x_curr = x[row].copy()\n",
    "\n",
    "        # make sure\n",
    "        if len(x_curr.shape) == 3 and x_curr.shape[2] == 1:\n",
    "            x_curr = x_curr.reshape(x_curr.shape[:2])\n",
    "        if x_curr.max() > 1:\n",
    "            x_curr /= 255.\n",
    "\n",
    "        # get a grayscale version of the image\n",
    "        if len(x_curr.shape) == 3 and x_curr.shape[2] == 3:\n",
    "            x_curr_gray = (0.2989 * x_curr[:,:,0] + 0.5870 * x_curr[:,:,1] + 0.1140 * x_curr[:,:,2]) # rgb to gray\n",
    "        else:\n",
    "            x_curr_gray = x_curr\n",
    "\n",
    "        axes[row,0].imshow(x_curr, cmap=plt.get_cmap('gray'))\n",
    "        axes[row,0].axis('off')\n",
    "        if len(shap_values[0][row].shape) == 2:\n",
    "            abs_vals = np.stack([np.abs(shap_values[i]) for i in range(len(shap_values))], 0).flatten()\n",
    "        else:\n",
    "            abs_vals = np.stack([np.abs(shap_values[i].sum(-1)) for i in range(len(shap_values))], 0).flatten()\n",
    "        max_val = np.nanpercentile(abs_vals, 99.9)\n",
    "        for i in range(len(shap_values)):\n",
    "            if labels is not None:\n",
    "                axes[row,i+1].set_title(labels[row,i], **label_kwargs)\n",
    "            sv = shap_values[i][row] if len(shap_values[i][row].shape) == 2 else shap_values[i][row].sum(-1)\n",
    "            axes[row,i+1].imshow(x_curr_gray, cmap=plt.get_cmap('gray'), alpha=1, extent=(-1, sv.shape[1], sv.shape[0], -1))\n",
    "            im = axes[row,i+1].imshow(sv, cmap=colors.red_transparent_blue, vmin=-max_val, vmax=max_val)\n",
    "            axes[row,i+1].axis('off')\n",
    "    if hspace == 'auto':\n",
    "        fig.tight_layout()\n",
    "    else:\n",
    "        fig.subplots_adjust(hspace=hspace)\n",
    "    \"\"\"cb = fig.colorbar(im, ax=np.ravel(axes).tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=fig_size[0]/aspect)\n",
    "    cb.outline.set_visible(False)\"\"\"\n",
    "    print(exp)\n",
    "    plt.savefig(\"tmp.png\")\n",
    "    if(org == 1):\n",
    "        im_heat = crop_img(org) # get original image\n",
    "    elif(org == 2):\n",
    "        im_heat = crop_img(org)\n",
    "    else:\n",
    "        im_heat = crop_img(0) #always get heatmap\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return im_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(img_arr, cols = 5):\n",
    "    ind = 0 #index\n",
    "    rows = math.ceil(len(img_arr)/cols)\n",
    "    img_w, img_h = img_arr[0].size\n",
    "    background = Image.new('RGBA',(img_w*cols + 10 * (cols+1), img_h*rows + 10*(rows+1)), (255, 255, 255, 255))\n",
    "    bg_w, bg_h = background.size\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            offset = (10 + c*img_w, 10+r*img_h)\n",
    "            background.paste(img_arr[ind],offset)\n",
    "            ind+=1\n",
    "            if(ind == len(img_arr)):\n",
    "                break\n",
    "    background.save(base_out + \"grid_\" + str(img_id) + \".png\")\n",
    "    print(\"saved at\", base_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deconvnet\n",
      "2448 460\n",
      "deconvnet\n",
      "2448 460\n",
      "deconvnet\n",
      "2448 460\n",
      "deep_taylor\n",
      "2448 460\n",
      "deeplift\n",
      "2448 460\n",
      "gradient\n",
      "2448 460\n",
      "guided_backprop\n",
      "2448 460\n",
      "input_t_gradient\n",
      "2448 460\n",
      "integrated_gradients\n",
      "2448 460\n",
      "lrp.epsilon\n",
      "2448 460\n",
      "occlusion\n",
      "2448 460\n",
      "saliency\n",
      "2448 460\n",
      "shap_rand\n",
      "2448 460\n",
      "shap_select\n",
      "2448 460\n",
      "smoothgrad\n",
      "2448 460\n",
      "saved at OCT-annotations/output_paper/\n",
      "deconvnet\n",
      "2448 460\n",
      "deconvnet\n",
      "2448 460\n",
      "deconvnet\n",
      "2448 460\n",
      "deep_taylor\n",
      "2448 460\n",
      "deeplift\n",
      "2448 460\n",
      "gradient\n",
      "2448 460\n",
      "guided_backprop\n",
      "2448 460\n",
      "input_t_gradient\n",
      "2448 460\n",
      "integrated_gradients\n",
      "2448 460\n",
      "lrp.epsilon\n",
      "2448 460\n",
      "occlusion\n",
      "2448 460\n",
      "saliency\n",
      "2448 460\n",
      "shap_rand\n",
      "2448 460\n",
      "shap_select\n",
      "2448 460\n",
      "smoothgrad\n",
      "2448 460\n",
      "saved at OCT-annotations/output_paper/\n",
      "deconvnet\n",
      "2448 460\n",
      "deconvnet\n",
      "2448 460\n",
      "deconvnet\n",
      "2448 460\n",
      "deep_taylor\n",
      "2448 460\n",
      "deeplift\n",
      "2448 460\n",
      "gradient\n",
      "2448 460\n",
      "guided_backprop\n",
      "2448 460\n",
      "input_t_gradient\n",
      "2448 460\n",
      "integrated_gradients\n",
      "2448 460\n",
      "lrp.epsilon\n",
      "2448 460\n",
      "occlusion\n",
      "2448 460\n",
      "saliency\n",
      "2448 460\n",
      "shap_rand\n",
      "2448 460\n",
      "shap_select\n",
      "2448 460\n",
      "smoothgrad\n",
      "2448 460\n",
      "saved at OCT-annotations/output_paper/\n"
     ]
    }
   ],
   "source": [
    "for cat in range(3):\n",
    "    img_mark, im_path = load_marked(cat)\n",
    "    for num in range(cat_img[cat],cat_img[cat] + 1):\n",
    "        arr_img = [] #array of original and all methods\n",
    "        for i, exp in enumerate(explainers):\n",
    "            filename = base + exp + '_model_' + str(0) + '.npy'\n",
    "            arr = np.load(filename)\n",
    "            img, img_id = load_img(cat)\n",
    "            #img_mod = np.array([resize(x_test[cat][num], img.shape)]) #change resizing method\n",
    "            #print(img_mod.shape)\n",
    "    \n",
    "            heatmap = np.array([resize(arr[cat][num], img.shape)])\n",
    "    \n",
    "            if i == 0:\n",
    "                arr_img.append(img_plot(heatmap, np.array([img]), exp, org = 1)) #to get original\n",
    "                arr_img.append(img_plot(heatmap, np.array([img_mark]), exp, org = 2))\n",
    "            if i == 8: #marked instead of LRP Z\n",
    "                #img_mark = np.array([resize(x_test[cat][num], img_mark.shape)])\n",
    "                #print(img_mark.shape)\n",
    "                #arr_img.append(img_plot(heatmap, np.array([img_mark]), exp, org = 2))\n",
    "                continue\n",
    "            arr_img.append(img_plot(heatmap, np.array([img]), exp))\n",
    "    \n",
    "        make_grid(arr_img)\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

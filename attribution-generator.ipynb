{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "import numpy as np \n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from jupyterthemes import jtplot\n",
    "import innvestigate\n",
    "import shap\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "from sklearn.preprocessing import normalize\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)\n",
    "from PIL import *\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base = \"/../../../scratch/amitoj/OCT2017/\"\n",
    "base = \"../../hdd/Amitoj/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('annot_keras.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 299, 299, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([[0 for i in range(x_test.shape[0])], [1 for i in range(x_test.shape[0])], [2 for i in range(x_test.shape[0])], [3 for i in range(x_test.shape[0])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = InceptionV3(include_top=True, weights= None, classes=4)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "weight_addrs = glob.glob('../Kermany_inception/top_weights/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5', '../Kermany_inception/top_weights/inceptionV3-03-0.9960.hdf5', '../Kermany_inception/top_weights/inceptionV3-04-0.9900.hdf5', '../Kermany_inception/top_weights/inceptionV3-04-0.9960.hdf5', '../Kermany_inception/top_weights/inceptionV3-04-1.0000.hdf5', '../Kermany_inception/top_weights/inceptionV3-06-0.9930.hdf5', '../Kermany_inception/top_weights/inceptionV3-08-0.9970.hdf5', '../Kermany_inception/top_weights/inceptionV3-09-0.9930.hdf5', '../Kermany_inception/top_weights/inceptionV3-10-0.9930.hdf5', '../Kermany_inception/top_weights/inceptionV3-16-0.9990.hdf5']"
      ],
      "text/plain": [
       "['../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-03-0.9960.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-04-0.9900.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-04-0.9960.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-04-1.0000.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-06-0.9930.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-08-0.9970.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-09-0.9930.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-10-0.9930.hdf5',\n",
       " '../Kermany_inception/top_weights/inceptionV3-16-0.9990.hdf5']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_addrs.sort()\n",
    "weight_addrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(base + 'small_train_norm.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background for shap\n",
    "#load background distribution\n",
    "randomlist = [479, 922, 491, 450, 1017, 1295, 988, 240, 809, 904, 621, 20, 141, 366, 373, 1110, 1003, 1149, 135, 94]\n",
    "x_train = np.empty((x.shape[0], 299, 299,3))\n",
    "for i, img in enumerate(x):\n",
    "    x_small = cv2.cvtColor(cv2.resize(img, dsize=(299,299), \n",
    "                                            interpolation=cv2.INTER_CUBIC), cv2.COLOR_GRAY2RGB)\n",
    "    x_train[i] = x_small\n",
    "background = x_train[randomlist]\n",
    "# Create explainer using this background\n",
    "# explain predictions of the model on three images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating shap_rand explainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value batch_normalization_38/moving_variance\n\t [[node batch_normalization_38/moving_variance/read (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402) ]]\n\t [[node predictions/Softmax (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3231) ]]\n\nCaused by op 'batch_normalization_38/moving_variance/read', defined at:\n  File \"/home/amitoj/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/amitoj/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/amitoj/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/amitoj/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/amitoj/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-9017a59abf47>\", line 1, in <module>\n    model = InceptionV3(include_top=True, weights= None, classes=4)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/applications/__init__.py\", line 28, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/applications/inception_v3.py\", line 11, in InceptionV3\n    return inception_v3.InceptionV3(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras_applications/inception_v3.py\", line 259, in InceptionV3\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras_applications/inception_v3.py\", line 79, in conv2d_bn\n    x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/layers/normalization.py\", line 129, in build\n    trainable=False)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 252, in add_weight\n    constraint=constraint)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value batch_normalization_38/moving_variance\n\t [[node batch_normalization_38/moving_variance/read (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402) ]]\n\t [[node predictions/Softmax (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3231) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value batch_normalization_38/moving_variance\n\t [[{{node batch_normalization_38/moving_variance/read}}]]\n\t [[{{node predictions/Softmax}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c82e057ae452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" explainer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# over 4 classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shap/explainers/deep/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_phase_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shap/explainers/deep/deep_tf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have provided over 5k background samples! For better performance consider using smaller random sample.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shap/explainers/deep/deep_tf.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase_flags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value batch_normalization_38/moving_variance\n\t [[node batch_normalization_38/moving_variance/read (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402) ]]\n\t [[node predictions/Softmax (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3231) ]]\n\nCaused by op 'batch_normalization_38/moving_variance/read', defined at:\n  File \"/home/amitoj/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/amitoj/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/amitoj/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/amitoj/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/amitoj/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-9017a59abf47>\", line 1, in <module>\n    model = InceptionV3(include_top=True, weights= None, classes=4)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/applications/__init__.py\", line 28, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/applications/inception_v3.py\", line 11, in InceptionV3\n    return inception_v3.InceptionV3(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras_applications/inception_v3.py\", line 259, in InceptionV3\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras_applications/inception_v3.py\", line 79, in conv2d_bn\n    x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/layers/normalization.py\", line 129, in build\n    trainable=False)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 252, in add_weight\n    constraint=constraint)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/amitoj/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value batch_normalization_38/moving_variance\n\t [[node batch_normalization_38/moving_variance/read (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402) ]]\n\t [[node predictions/Softmax (defined at /home/amitoj/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3231) ]]\n"
     ]
    }
   ],
   "source": [
    "keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "for exp in ['shap_rand']:\n",
    "    print(\"\\n\")\n",
    "    for w_num, w in enumerate(weight_addrs):\n",
    "        arr = []\n",
    "        print(\"Loading \" + w)\n",
    "        model.load_weights(w)\n",
    "        pred_arr = []\n",
    "        for cl in range(3):\n",
    "            pred_arr.append(model.predict(x_test[cl]))\n",
    "        #pred_arr\n",
    "        Y_pred = np.argmax(np.array(pred_arr), axis = 2)\n",
    "        print(\"Creating \" + str(exp) + \" explainer...\")\n",
    "        e = shap.DeepExplainer(model, background)\n",
    "    \n",
    "        for cat in range(3): # over 4 classes\n",
    "            # predicting for the images in the ind_img arr\n",
    "            print(\"Finding \" + exp + \" for class \" + str(cat))\n",
    "            a_curr = []\n",
    "            sh = e.shap_values(x_test[cat][:]) #loading shap values for the correct class, sh is a list of len 4\n",
    "            sh_arr = np.array(sh)\n",
    "            print(sh_arr.shape)\n",
    "            sh_new = []\n",
    "            for ind in range(sh_arr.shape[1]):\n",
    "                sh_new.append(sh_arr[Y_pred[cat][ind]][ind])\n",
    "            sh = np.array(sh_new)\n",
    "            sv = np.sum(sh, axis = 3) # adding for all 3 channels\n",
    "            sv /= (np.abs(sv).max())\n",
    "            print(sv.shape)\n",
    "            arr.append(sv) # arr will have sv of all 4 classes\n",
    "        arr = np.array(arr)\n",
    "        print(arr.shape)\n",
    "        np.save('OCT-annotations/attributions_10_all/' + exp + '_model_' + str(w_num), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'guided_backprop', 'deep_taylor', 'input_t_gradient', 'lrp.z', 'lrp.epsilon', 'integrated_gradients', 'deconvnet'\n",
    "explainers = ['guided_backprop', 'deep_taylor', 'input_t_gradient', 'lrp.z', 'lrp.epsilon', 'integrated_gradients', 'deconvnet', 'smoothgrad', 'gradient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating guided_backpropexplainer...\n",
      "Finding guided_backpropfor class 0\n",
      "Finding guided_backpropfor class 1\n",
      "Finding guided_backpropfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating deep_taylorexplainer...\n",
      "Finding deep_taylorfor class 0\n",
      "Finding deep_taylorfor class 1\n",
      "Finding deep_taylorfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating input_t_gradientexplainer...\n",
      "Finding input_t_gradientfor class 0\n",
      "Finding input_t_gradientfor class 1\n",
      "Finding input_t_gradientfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating lrp.zexplainer...\n",
      "Finding lrp.zfor class 0\n",
      "Finding lrp.zfor class 1\n",
      "Finding lrp.zfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating lrp.epsilonexplainer...\n",
      "Finding lrp.epsilonfor class 0\n",
      "Finding lrp.epsilonfor class 1\n",
      "Finding lrp.epsilonfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating integrated_gradientsexplainer...\n",
      "Finding integrated_gradientsfor class 0\n",
      "Finding integrated_gradientsfor class 1\n",
      "Finding integrated_gradientsfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating deconvnetexplainer...\n",
      "Finding deconvnetfor class 0\n",
      "Finding deconvnetfor class 1\n",
      "Finding deconvnetfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating smoothgradexplainer...\n",
      "Finding smoothgradfor class 0\n",
      "Finding smoothgradfor class 1\n",
      "Finding smoothgradfor class 2\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating gradientexplainer...\n",
      "Finding gradientfor class 0\n",
      "Finding gradientfor class 1\n",
      "Finding gradientfor class 2\n",
      "(3, 20, 299, 299)\n"
     ]
    }
   ],
   "source": [
    "for exp in explainers:\n",
    "    print(\"\\n\")\n",
    "    for w_num, w in enumerate(weight_addrs[0:1]):\n",
    "        arr = []\n",
    "        print(\"Loading \" + w)\n",
    "        model.load_weights(w)\n",
    "        print(\"Creating \" + str(exp) + \"explainer...\")\n",
    "        analyzer = innvestigate.create_analyzer(exp, innvestigate.utils.keras.graph.model_wo_softmax(model))\n",
    "    \n",
    "        for cat in range(3): # over 4 classes\n",
    "            # predicting for the images in the ind_img arr\n",
    "            print(\"Finding \" + exp + \"for class \" + str(cat))\n",
    "            a_curr = []\n",
    "            for ind in range(0,x_test.shape[1],1):\n",
    "                a = analyzer.analyze(x_test[cat][ind:ind+1])\n",
    "            # Aggregate along color channels and normalize to [-1, 1]\n",
    "                a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "                a /= np.max(np.abs(a))\n",
    "                a_curr.append(a[0])\n",
    "            a_c = np.array(a_curr)\n",
    "            arr.append(np.asarray(a_c))        \n",
    "        arr = np.array(arr)\n",
    "        print(arr.shape)\n",
    "        np.save('OCT-annotations/attributions_20_new/' + exp + '_model_' + str(w_num), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('train_select_keras.npy')\n",
    "background = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in ['shap_select']:\n",
    "    print(\"\\n\")\n",
    "    for w_num, w in enumerate(weight_addrs):\n",
    "        arr = []\n",
    "        print(\"Loading \" + w)\n",
    "        model.load_weights(w)\n",
    "        pred_arr = []\n",
    "        for cl in range(3):\n",
    "            pred_arr.append(model.predict(x_test[cl]))\n",
    "        #pred_arr\n",
    "        Y_pred = np.argmax(np.array(pred_arr), axis = 2)\n",
    "        print(\"Creating \" + str(exp) + \" explainer...\")\n",
    "        e = shap.DeepExplainer(model, background)\n",
    "    \n",
    "        for cat in range(3): # over 4 classes\n",
    "            # predicting for the images in the ind_img arr\n",
    "            print(\"Finding \" + exp + \" for class \" + str(cat))\n",
    "            a_curr = []\n",
    "            sh = e.shap_values(x_test[cat][:]) #loading shap values for the correct class, sh is a list of len 4\n",
    "            sh_arr = np.array(sh)\n",
    "            print(sh_arr.shape)\n",
    "            sh_new = []\n",
    "            for ind in range(sh_arr.shape[1]):\n",
    "                sh_new.append(sh_arr[Y_pred[cat][ind]][ind])\n",
    "            sh = np.array(sh_new)\n",
    "            sv = np.sum(sh, axis = 3) # adding for all 3 channels\n",
    "            sv /= (np.abs(sv).max())\n",
    "            print(sv.shape)\n",
    "            arr.append(sv) # arr will have sv of all 4 classes\n",
    "        arr = np.array(arr)\n",
    "        print(arr.shape)\n",
    "        np.save('OCT-annotations/attributions_20_new/' + exp + '_model_' + str(w_num), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainers = ['saliency', 'deeplift', 'occlusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating saliency explainer...\n",
      "Finding saliency for class 0\n",
      "(20, 299, 299)\n",
      "Finding saliency for class 1\n",
      "(20, 299, 299)\n",
      "Finding saliency for class 2\n",
      "(20, 299, 299)\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating deeplift explainer...\n",
      "Finding deeplift for class 0\n",
      "(20, 299, 299)\n",
      "Finding deeplift for class 1\n",
      "(20, 299, 299)\n",
      "Finding deeplift for class 2\n",
      "(20, 299, 299)\n",
      "(3, 20, 299, 299)\n",
      "\n",
      "\n",
      "Loading ../Kermany_inception/top_weights/inceptionV3-02-0.9910.hdf5\n",
      "Creating occlusion explainer...\n",
      "Finding occlusion for class 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in true_divide\n",
      "Attributions generated by Occlusion method contain nans, probably because window_shape and step do not allow to cover the all input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 299, 299)\n",
      "Finding occlusion for class 1\n",
      "(20, 299, 299)\n",
      "Finding occlusion for class 2\n",
      "(20, 299, 299)\n",
      "(3, 20, 299, 299)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "ind_img = [i for i in range(0,250,1)] # selecting images from each class\n",
    "for exp in explainers:\n",
    "    print(\"\\n\")\n",
    "    for w_num, w in enumerate(weight_addrs[0:1]):\n",
    "        arr = []\n",
    "        print(\"Loading \" + w)\n",
    "        model.load_weights(w)\n",
    "        \n",
    "        pred_arr = []\n",
    "        for cl in range(3):\n",
    "            pred_arr.append(model.predict(x_test[cl]))\n",
    "        Y_pred = np.argmax(np.array(pred_arr), axis = 2)\n",
    "        \n",
    "        print(\"Creating \" + str(exp) + \" explainer...\")\n",
    "        input_tensor = model.layers[0].input\n",
    "        fModel = Model(inputs=input_tensor, outputs = model.layers[-1].output) #excluding dense layer\n",
    "        target_tensor = fModel(input_tensor)\n",
    "        for cat in range(3): # over 4 classes\n",
    "            # predicting for the images in the ind_img arr\n",
    "            print(\"Finding \" + exp + \" for class \" + str(cat))\n",
    "            with DeepExplain(session=K.get_session()) as de:\n",
    "                xs = x_test[cat]\n",
    "                ys = keras.utils.to_categorical(Y_pred[cat], 4)\n",
    "                if(exp == 'occlusion'):\n",
    "                    a = de.explain('occlusion', target_tensor, input_tensor, xs, ys=ys, window_shape=[64,64,3],  step=16, batch_size=40)\n",
    "                    a = np.nan_to_num(a)\n",
    "                else:\n",
    "                    a = de.explain(exp, target_tensor, input_tensor, xs, ys=ys, batch_size=40)\n",
    "                a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "                a /= np.max(np.abs(a))\n",
    "            a_c = np.array(a)\n",
    "            arr.append(np.asarray(a_c))\n",
    "            print(a_c.shape)\n",
    "        arr = np.array(arr)\n",
    "        print(arr.shape)\n",
    "        np.save('OCT-annotations/attributions_20_new//' + exp + '_model_' + str(w_num), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
